# å¤šæ§˜æƒ…å ±æºå¯¾å¿œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸

**Project**: TradingAssistantX å¤šæ§˜æƒ…å ±æºå¯¾å¿œ  
**Manager**: Claude Code Manager  
**Version**: v2.0  
**Date**: 2025-01-21  

## ğŸ—ï¸ **ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦**

æ—¢å­˜ã®Xç‰¹åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’æ‹¡å¼µã—ã€RSSã€APIã€Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç­‰ã®å¤šæ§˜ãªæƒ…å ±æºã«å¯¾å¿œã—ãŸçµ±åˆæƒ…å ±åé›†ã‚·ã‚¹ãƒ†ãƒ ã«ç™ºå±•ã•ã›ã‚‹ã€‚

### è¨­è¨ˆåŸå‰‡
1. **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ç¶™æ‰¿**: ActionSpecificCollectorã€Claude SDKé€£æºã‚’ç¶­æŒ
2. **æ®µéšçš„ç§»è¡Œ**: Xæ©Ÿèƒ½ã‚’æ®‹ã—ãªãŒã‚‰æ–°æ©Ÿèƒ½ã‚’è¿½åŠ 
3. **YAMLé§†å‹•ç¶™ç¶š**: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ã®ç¶™ç¶š
4. **å“è³ªæœ€å„ªå…ˆ**: æƒ…å ±å“è³ªã¨ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ã®ç¢ºä¿

## ğŸ”„ **æ–°æ—§ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

### å…¨ä½“ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

```mermaid
graph TB
    subgraph "Multi-Source Collection Layer"
        MSC[MultiSourceCollector]
        RSS[RSS Collector]
        API[API Collector] 
        WEB[Web Scraper]
        SOCIAL[Social Collector]
        LEGACY[Legacy X Collector]
    end
    
    subgraph "Data Processing Layer"
        DN[Data Normalizer]
        QA[Quality Assessor]
        DD[Duplicate Detector]
        CF[Content Filter]
    end
    
    subgraph "Existing Core System"
        ASC[ActionSpecificCollector]
        CMI[Claude Max Integration]
        DE[Decision Engine]
    end
    
    subgraph "Unified Data Layer"
        UDS[Unified Data Store]
        CONFIG[Multi-Source Config]
        CACHE[Data Cache]
    end
    
    MSC --> RSS
    MSC --> API
    MSC --> WEB
    MSC --> SOCIAL
    MSC --> LEGACY
    
    RSS --> DN
    API --> DN
    WEB --> DN
    SOCIAL --> DN
    LEGACY --> DN
    
    DN --> QA
    QA --> DD
    DD --> CF
    CF --> UDS
    
    UDS --> ASC
    ASC --> CMI
    CMI --> DE
    
    CONFIG --> MSC
    UDS --> CACHE
```

## ğŸ“‹ **ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°è¨­è¨ˆ**

### 1. **MultiSourceCollector** (æ–°è¦)

```typescript
export class MultiSourceCollector {
  private rssCollector: RSSCollector;
  private apiCollector: APICollector;
  private webScraper: WebScraper;
  private socialCollector: SocialCollector;
  private legacyCollector: LegacyXCollector;
  
  constructor(config: MultiSourceConfig) {
    this.initializeCollectors(config);
  }
  
  // çµ±åˆåé›†ãƒ¡ã‚½ãƒƒãƒ‰
  async collectFromAllSources(
    requirements: CollectionRequirements
  ): Promise<CollectedData[]> {
    const collections = await Promise.allSettled([
      this.rssCollector.collect(requirements.rss),
      this.apiCollector.collect(requirements.api),
      this.webScraper.collect(requirements.web),
      this.socialCollector.collect(requirements.social),
      this.legacyCollector.collect(requirements.legacy) // æ—¢å­˜Xåé›†
    ]);
    
    return this.processCollectionResults(collections);
  }
  
  // å„ªå…ˆåº¦ä»˜ãåé›†ï¼ˆç·Šæ€¥æ™‚ï¼‰
  async collectPrioritized(
    priority: 'high' | 'medium' | 'low'
  ): Promise<CollectedData[]> {
    const sources = this.getSources

    return this.executePrioritizedCollection(sources);
  }
}
```

### 2. **RSSCollector** (æ–°è¦)

```typescript
export class RSSCollector implements DataCollector {
  private parser: RSSParser;
  private config: RSSConfig;
  
  async collect(requirements: RSSRequirements): Promise<RSSData[]> {
    const feeds = this.selectFeeds(requirements);
    const results: RSSData[] = [];
    
    for (const feed of feeds) {
      try {
        const parsed = await this.parser.parseURL(feed.url);
        const filtered = this.filterByQuality(parsed.items, feed.qualityThreshold);
        const normalized = this.normalizeRSSData(filtered, feed);
        
        results.push(...normalized);
      } catch (error) {
        console.error(`RSS collection failed for ${feed.name}:`, error);
        // Continue with other feeds
      }
    }
    
    return results;
  }
  
  private filterByQuality(items: any[], threshold: number): any[] {
    return items.filter(item => {
      const quality = this.calculateRSSQuality(item);
      return quality >= threshold;
    });
  }
  
  private calculateRSSQuality(item: any): number {
    let score = 0;
    
    // Content length check
    if (item.contentSnippet?.length > 100) score += 0.3;
    
    // Freshness check (within 24 hours)
    const age = Date.now() - new Date(item.pubDate).getTime();
    if (age < 24 * 60 * 60 * 1000) score += 0.3;
    
    // Title quality check
    if (this.hasFinancialKeywords(item.title)) score += 0.4;
    
    return Math.min(score, 1.0);
  }
}
```

### 3. **APICollector** (æ–°è¦)

```typescript
export class APICollector implements DataCollector {
  private rateLimiter: RateLimiterFlexible;
  private apiClients: Map<string, APIClient>;
  
  constructor(config: APIConfig) {
    this.initializeClients(config);
    this.rateLimiter = new RateLimiterFlexible({
      keyPrefix: 'api_collector',
      points: config.maxRequestsPerHour,
      duration: 3600, // 1 hour
    });
  }
  
  async collect(requirements: APIRequirements): Promise<APIData[]> {
    const results: APIData[] = [];
    
    for (const apiConfig of requirements.apis) {
      try {
        await this.rateLimiter.consume(apiConfig.name);
        
        const client = this.apiClients.get(apiConfig.name);
        const data = await client.fetchData(apiConfig.query);
        const normalized = this.normalizeAPIData(data, apiConfig);
        
        results.push(...normalized);
      } catch (rateLimitError) {
        console.warn(`Rate limit hit for ${apiConfig.name}, skipping`);
      }
    }
    
    return results;
  }
  
  // NewsAPIçµ±åˆä¾‹
  async collectFromNewsAPI(query: NewsQuery): Promise<APIData[]> {
    const client = this.apiClients.get('newsapi');
    const response = await client.request({
      endpoint: '/everything',
      params: {
        q: query.keywords.join(' OR '),
        sortBy: 'publishedAt',
        language: 'en',
        pageSize: 20
      }
    });
    
    return this.normalizeNewsAPIResponse(response.articles);
  }
}
```

### 4. **WebScraper** (Playwrightæ‹¡å¼µ)

```typescript
export class WebScraper implements DataCollector {
  private browserManager: PlaywrightBrowserManager; // æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ æ´»ç”¨
  private robotsChecker: RobotsChecker;
  
  async collect(requirements: WebScrapingRequirements): Promise<WebData[]> {
    const results: WebData[] = [];
    
    for (const target of requirements.targets) {
      // robots.txt ãƒã‚§ãƒƒã‚¯
      if (!(await this.robotsChecker.isAllowed(target.url))) {
        console.warn(`Scraping not allowed for ${target.url}`);
        continue;
      }
      
      try {
        const data = await this.scrapeWebsite(target);
        results.push(...data);
      } catch (error) {
        console.error(`Scraping failed for ${target.url}:`, error);
      }
    }
    
    return results;
  }
  
  private async scrapeWebsite(target: WebTarget): Promise<WebData[]> {
    const browser = await this.browserManager.getBrowser();
    const page = await browser.newPage();
    
    try {
      await page.goto(target.url, { waitUntil: 'networkidle' });
      
      // å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®èª­ã¿è¾¼ã¿å¾…æ©Ÿ
      if (target.waitForSelector) {
        await page.waitForSelector(target.waitForSelector, { timeout: 10000 });
      }
      
      // ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
      const extractedData = await page.evaluate((selectors) => {
        const title = document.querySelector(selectors.title)?.textContent;
        const content = document.querySelector(selectors.content)?.textContent;
        const publishedAt = document.querySelector(selectors.date)?.textContent;
        
        return { title, content, publishedAt };
      }, target.selectors);
      
      return [this.normalizeWebData(extractedData, target)];
    } finally {
      await page.close();
    }
  }
}
```

### 5. **ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ãƒ»çµ±åˆã‚·ã‚¹ãƒ†ãƒ **

```typescript
export class DataNormalizer {
  // ç•°ãªã‚‹æƒ…å ±æºã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€å½¢å¼ã«å¤‰æ›
  normalize(rawData: any, source: DataSource): NormalizedData {
    switch (source.type) {
      case 'rss':
        return this.normalizeRSSData(rawData, source);
      case 'api':
        return this.normalizeAPIData(rawData, source);
      case 'web':
        return this.normalizeWebData(rawData, source);
      case 'social':
        return this.normalizeSocialData(rawData, source);
      case 'legacy_x':
        return this.normalizeLegacyXData(rawData, source); // æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›
      default:
        throw new Error(`Unknown source type: ${source.type}`);
    }
  }
  
  // å“è³ªã‚¹ã‚³ã‚¢çµ±ä¸€è¨ˆç®—
  calculateQualityScore(data: NormalizedData): number {
    const weights = {
      contentRelevance: 0.3,
      sourceCredibility: 0.25,
      timelinessScore: 0.2,
      uniquenessScore: 0.15,
      readabilityScore: 0.1
    };
    
    return Object.entries(weights).reduce((score, [metric, weight]) => {
      return score + (data.qualityMetrics[metric] * weight);
    }, 0);
  }
}

export class DuplicateDetector {
  private threshold = 0.85; // 85%ä»¥ä¸Šã®é¡ä¼¼åº¦ã§é‡è¤‡åˆ¤å®š
  
  detectDuplicates(dataList: NormalizedData[]): NormalizedData[] {
    const uniqueData: NormalizedData[] = [];
    
    for (const item of dataList) {
      if (!this.isDuplicate(item, uniqueData)) {
        uniqueData.push(item);
      }
    }
    
    return uniqueData;
  }
  
  private isDuplicate(item: NormalizedData, existingData: NormalizedData[]): boolean {
    for (const existing of existingData) {
      const similarity = this.calculateSimilarity(item.content, existing.content);
      if (similarity >= this.threshold) {
        return true;
      }
    }
    return false;
  }
  
  private calculateSimilarity(text1: string, text2: string): number {
    // Jaccardé¡ä¼¼åº¦è¨ˆç®—
    const set1 = new Set(text1.toLowerCase().split(/\s+/));
    const set2 = new Set(text2.toLowerCase().split(/\s+/));
    
    const intersection = new Set([...set1].filter(x => set2.has(x)));
    const union = new Set([...set1, ...set2]);
    
    return intersection.size / union.size;
  }
}
```

## ğŸ“Š **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ **

### å¤šæ§˜æƒ…å ±æºè¨­å®š (`data/multi-source-config.yaml`)

```yaml
version: "2.0.0"
lastUpdated: "2025-01-21T10:00:00Z"

# å…¨èˆ¬è¨­å®š
global:
  enabled: true
  fallbackToLegacy: true  # X ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
  maxConcurrentSources: 5
  collectionTimeout: 300  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  qualityThreshold: 0.7

# RSS ãƒ•ã‚£ãƒ¼ãƒ‰è¨­å®š
rss:
  enabled: true
  updateInterval: 30  # 30åˆ†é–“éš”
  maxFeedsPerCycle: 10
  sources:
    - name: "bloomberg-markets"
      url: "https://feeds.bloomberg.com/markets/news.rss"
      category: "financial_news"
      priority: "high"
      qualityThreshold: 0.8
      tags: ["bloomberg", "markets", "news"]
      
    - name: "reuters-finance"
      url: "https://feeds.reuters.com/news/wealth"
      category: "financial_news"
      priority: "high"
      qualityThreshold: 0.8
      tags: ["reuters", "finance", "wealth"]
      
    - name: "investopedia-education"
      url: "https://www.investopedia.com/feedbuilder/feed/getfeed"
      category: "educational"
      priority: "medium"
      qualityThreshold: 0.75
      tags: ["investopedia", "education", "trading"]

# API è¨­å®š
apis:
  enabled: true
  rateLimitStrategy: "adaptive"
  maxRequestsPerHour: 1000
  sources:
    - name: "newsapi"
      type: "news_aggregator"
      endpoint: "https://newsapi.org/v2/everything"
      apiKeyEnv: "NEWSAPI_KEY"
      category: "general_news"
      priority: "high"
      requestLimit: 100  # per hour
      queryTemplates:
        - "trading AND (stocks OR forex)"
        - "investment AND education"
        - "financial AND markets"
        
    - name: "alpha_vantage"
      type: "financial_data"
      endpoint: "https://www.alphavantage.co/query"
      apiKeyEnv: "ALPHA_VANTAGE_KEY"
      category: "market_data"
      priority: "medium"
      requestLimit: 25   # per hour (free tier)

# Web ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š
webScraping:
  enabled: true
  respectRobots: true
  maxConcurrent: 3
  defaultTimeout: 30
  sources:
    - name: "yahoo-finance"
      baseUrl: "https://finance.yahoo.com"
      category: "financial_news"
      priority: "high"
      selectors:
        title: "h1[data-module=ArticleHeader]"
        content: ".caas-body"
        date: ".caas-attr-meta-time"
      updateInterval: 60  # 1æ™‚é–“é–“éš”
      
    - name: "marketwatch"
      baseUrl: "https://www.marketwatch.com"
      category: "market_analysis"
      priority: "medium"
      selectors:
        title: ".article__headline"
        content: ".article__body"
        date: ".article__timestamp"
      updateInterval: 90

# ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢è¨­å®šï¼ˆå°†æ¥æ‹¡å¼µï¼‰
social:
  enabled: false  # æ®µéšçš„ã«æœ‰åŠ¹åŒ–
  sources:
    - name: "reddit-investing"
      platform: "reddit"
      subreddit: "investing"
      priority: "low"
      postLimit: 10
      qualityThreshold: 0.6

# ãƒ¬ã‚¬ã‚·ãƒ¼X ã‚·ã‚¹ãƒ†ãƒ è¨­å®šï¼ˆæ—¢å­˜ç¶™ç¶šï¼‰
legacy_x:
  enabled: true  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ç¶™ç¶šä½¿ç”¨
  priority: "medium"
  useAsBackup: true
  config:
    # æ—¢å­˜ã®ActionSpecificCollectorè¨­å®šã‚’ç¶™æ‰¿
    testMode: true
    collectionStrategy: "fallback"
```

## ğŸ”„ **æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆãƒã‚¤ãƒ³ãƒˆ**

### ActionSpecificCollectorçµ±åˆ

```typescript
// æ—¢å­˜ã®ActionSpecificCollectorã‚’æ‹¡å¼µ
export class EnhancedActionSpecificCollector extends ActionSpecificCollector {
  private multiSourceCollector: MultiSourceCollector;
  
  constructor(
    playwrightEngine: PlaywrightEngine,
    multiSourceCollector: MultiSourceCollector
  ) {
    super(playwrightEngine);
    this.multiSourceCollector = multiSourceCollector;
  }
  
  // æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ‹¡å¼µ
  async collectForAction(
    actionType: ActionType,
    context: ActionContext,
    sufficiencyTarget: number = 85
  ): Promise<ActionSpecificResult> {
    console.log('ğŸ”„ [Enhanced Collection] å¤šæ§˜æƒ…å ±æºã‹ã‚‰åé›†é–‹å§‹...');
    
    try {
      // 1. å¤šæ§˜æƒ…å ±æºã‹ã‚‰åé›†
      const multiSourceData = await this.multiSourceCollector.collectFromAllSources({
        actionType,
        context,
        priority: this.determinePriority(actionType)
      });
      
      if (this.isSufficient(multiSourceData, sufficiencyTarget)) {
        return this.formatResult(multiSourceData, 'multi_source');
      }
      
      // 2. ä¸ååˆ†ãªå ´åˆã¯æ—¢å­˜ã®Xåé›†ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      console.log('âš ï¸ [Fallback] å¤šæ§˜æƒ…å ±æºãŒä¸ååˆ†ã€Xåé›†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯');
      const legacyResult = await super.collectForAction(actionType, context, sufficiencyTarget);
      
      // 3. çµæœã‚’çµ±åˆ
      return this.mergeResults(multiSourceData, legacyResult);
      
    } catch (error) {
      console.error('âŒ [Enhanced Collection Error]:', error);
      // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å®Œå…¨ã«æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      return super.collectForAction(actionType, context, sufficiencyTarget);
    }
  }
}
```

### Claude Max Integrationæ‹¡å¼µ

```typescript
// å¤šæ§˜æƒ…å ±æºå¯¾å¿œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‹¡å¼µ
export class EnhancedClaudeMaxIntegration extends ClaudeMaxIntegration {
  
  async generateStrategicPost(): Promise<GeneratedPost> {
    // æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æƒ…å ±æºå¤šæ§˜æ€§ã‚’è¿½åŠ 
    const enhancedPrompt = `
      ã‚ãªãŸã¯ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‘ã‘ã®ä¾¡å€¤ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
      
      ## åˆ©ç”¨å¯èƒ½ãªæƒ…å ±æº
      1. RSS ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆBloomberg, Reuters, Investopediaç­‰ï¼‰
      2. å…¬é–‹APIï¼ˆNewsAPI, Alpha Vantageç­‰ï¼‰
      3. Web ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆYahoo Finance, MarketWatchç­‰ï¼‰
      4. ãƒ¬ã‚¬ã‚·ãƒ¼X ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
      
      ## ã‚¿ã‚¹ã‚¯
      ä¸Šè¨˜ã®å¤šæ§˜ãªæƒ…å ±æºã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã€æ•™è‚²çš„ãªæŠ•ç¨¿å†…å®¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
      
      ## æ³¨æ„äº‹é …
      - è¤‡æ•°æƒ…å ±æºã®å†…å®¹ã‚’çµ„ã¿åˆã‚ã›ãŸä»˜åŠ ä¾¡å€¤ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
      - æƒ…å ±æºã®ä¿¡é ¼æ€§ã‚’è€ƒæ…®ã—ãŸå†…å®¹
      - Xä»¥å¤–ã®æƒ…å ±æºã‚’ç©æ¥µçš„ã«æ´»ç”¨
      
      ä¾¡å€¤ã‚ã‚‹çµ±åˆæŠ•ç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    `;
    
    return super.generateWithEnhancedPrompt(enhancedPrompt);
  }
}
```

## ğŸ“ˆ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æˆ¦ç•¥**

### 1. ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–

```typescript
export class ParallelCollectionManager {
  private maxConcurrency = 5;
  private collectionQueue: Queue<CollectionTask> = new Queue();
  
  async executeParallelCollection(tasks: CollectionTask[]): Promise<CollectedData[]> {
    const batches = this.createBatches(tasks, this.maxConcurrency);
    const results: CollectedData[] = [];
    
    for (const batch of batches) {
      const batchResults = await Promise.allSettled(
        batch.map(task => this.executeTask(task))
      );
      
      results.push(...this.processBatchResults(batchResults));
    }
    
    return results;
  }
}
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

```typescript
export class DataCacheManager {
  private cache = new Map<string, CachedData>();
  private maxCacheAge = 30 * 60 * 1000; // 30åˆ†
  
  async getCachedOrFetch(
    key: string, 
    fetcher: () => Promise<CollectedData[]>
  ): Promise<CollectedData[]> {
    const cached = this.cache.get(key);
    
    if (cached && !this.isExpired(cached)) {
      console.log(`ğŸ“„ [Cache Hit] ${key}`);
      return cached.data;
    }
    
    console.log(`ğŸ”„ [Cache Miss] ${key} - fetching fresh data`);
    const freshData = await fetcher();
    
    this.cache.set(key, {
      data: freshData,
      timestamp: Date.now()
    });
    
    return freshData;
  }
}
```

## ğŸ§ª **ãƒ†ã‚¹ãƒˆæˆ¦ç•¥**

### çµ±åˆãƒ†ã‚¹ãƒˆè¨­è¨ˆ

```typescript
describe('Multi-Source Collection Integration', () => {
  let multiSourceCollector: MultiSourceCollector;
  let mockConfig: MultiSourceConfig;
  
  beforeEach(() => {
    // ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã§ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
    mockConfig = createTestConfig();
    multiSourceCollector = new MultiSourceCollector(mockConfig);
  });
  
  test('should collect from RSS feeds successfully', async () => {
    const requirements = createRSSRequirements();
    const results = await multiSourceCollector.collectFromRSS(requirements);
    
    expect(results).toBeDefined();
    expect(results.length).toBeGreaterThan(0);
    expect(results[0].source).toBe('rss');
  });
  
  test('should fallback to legacy X collector on failure', async () => {
    // RSS/APIåé›†ã‚’æ„å›³çš„ã«å¤±æ•—ã•ã›ã‚‹
    jest.spyOn(multiSourceCollector, 'collectFromAllSources')
        .mockRejectedValue(new Error('Collection failed'));
    
    const results = await multiSourceCollector.collectPrioritized('high');
    
    // ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    expect(results).toBeDefined();
    expect(results.some(r => r.source === 'legacy_x')).toBe(true);
  });
});
```

## ğŸš€ **å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—**

### Phase 1: åŸºç›¤æ§‹ç¯‰ (Week 1)
- [ ] `MultiSourceCollector` åŸºæœ¬å®Ÿè£…
- [ ] `DataNormalizer` ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
- [ ] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ å®šç¾©
- [ ] åŸºæœ¬çš„ãªçµ±åˆãƒ†ã‚¹ãƒˆ

### Phase 2: RSS/APIçµ±åˆ (Week 2)
- [ ] `RSSCollector` å®Œå…¨å®Ÿè£…
- [ ] `APICollector` å®Œå…¨å®Ÿè£…
- [ ] NewsAPI, Yahoo Finance APIçµ±åˆ
- [ ] å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

### Phase 3: Webæ‹¡å¼µ (Week 3)
- [ ] `WebScraper` å¤šã‚µã‚¤ãƒˆå¯¾å¿œ
- [ ] robots.txtéµå®ˆã‚·ã‚¹ãƒ†ãƒ 
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–

### Phase 4: ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ (Week 4)
- [ ] æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®å®Œå…¨çµ±åˆ
- [ ] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Œæˆ
- [ ] ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ 
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

---

**Ready for Implementation**: ã“ã®è¨­è¨ˆã«åŸºã¥ãã€3åã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã¸ã®ã‚¿ã‚¹ã‚¯é…åˆ†ã‚’è¡Œã„ã¾ã™ã€‚